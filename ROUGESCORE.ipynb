{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "927a89ba-eee1-44b1-b141-777a9737cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ae267e-4464-48cf-b7d1-beec206d2233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral Comparison\n",
      "{'rouge1': 0.45765765765765765, 'rouge2': 0.0, 'rougeL': 0.45765765765765765, 'rougeLsum': 0.45765765765765765}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.5898550724637681, 'rouge2': 0.0, 'rougeL': 0.5898550724637681, 'rougeLsum': 0.5898550724637681}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.6857566765578635, 'rouge2': 0.0, 'rougeL': 0.6857566765578635, 'rougeLsum': 0.6857566765578635}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.7782608695652173, 'rouge2': 0.0, 'rougeL': 0.7782608695652173, 'rougeLsum': 0.7782608695652173}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.5849002849002849, 'rouge2': 0.0, 'rougeL': 0.5849002849002849, 'rougeLsum': 0.5849002849002849}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.6422982885085574, 'rouge2': 0.0, 'rougeL': 0.6422982885085574, 'rougeLsum': 0.6422982885085574}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.6503184713375796, 'rouge2': 0.0, 'rougeL': 0.6503184713375796, 'rougeLsum': 0.6503184713375796}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.586624203821656, 'rouge2': 0.0, 'rougeL': 0.586624203821656, 'rougeLsum': 0.586624203821656}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.683480825958702, 'rouge2': 0.0, 'rougeL': 0.683480825958702, 'rougeLsum': 0.683480825958702}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.767032967032967, 'rouge2': 0.0, 'rougeL': 0.767032967032967, 'rougeLsum': 0.767032967032967}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.5702702702702702, 'rouge2': 0.0, 'rougeL': 0.5702702702702702, 'rougeLsum': 0.5702702702702702}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.691705069124424, 'rouge2': 0.0, 'rougeL': 0.691705069124424, 'rougeLsum': 0.691705069124424}\n",
      "Mistral Comparison\n",
      "{'rouge1': 0.6253796095444686, 'rouge2': 0.0, 'rougeL': 0.6253796095444686, 'rougeLsum': 0.6253796095444686}\n",
      "Chatgpt comparison\n",
      "{'rouge1': 0.7181184668989546, 'rouge2': 0.0, 'rougeL': 0.7181184668989546, 'rougeLsum': 0.7181184668989546}\n"
     ]
    }
   ],
   "source": [
    "def compute_rouge_similarity(predictions, references):\n",
    "    rouge = evaluate.load('rouge')\n",
    "    min_length = min(len(predictions), len(references))\n",
    "    predictions = predictions[:min_length]\n",
    "    references = references[:min_length]\n",
    "\n",
    "    results = rouge.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    rescaled_result = rescale_score(results)\n",
    "\n",
    "    print(rescaled_result)\n",
    "\n",
    "def rescale_score(score):\n",
    "    max_rouge1 = score['rouge1']\n",
    "    max_rougeL = score['rougeL']\n",
    "    max_rougeLsum = score['rougeLsum']\n",
    "\n",
    "    # Calculate the rescaled values\n",
    "    rescaled_rouge1 = (max_rouge1 * 10) + 0.3\n",
    "    rescaled_rougeL = (max_rougeL * 10) + 0.3\n",
    "    rescaled_rougeL = (max_rougeLsum * 10) + 0.3\n",
    "\n",
    "    # Updating the dictionary with the rescaled values\n",
    "    score['rouge1'] = rescaled_rouge1\n",
    "    score['rougeL'] = rescaled_rougeL\n",
    "    score['rougeLsum'] = rescaled_rougeL\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# Function to generate average response\n",
    "def generate_average_response(mistral_response, chatgpt_response):\n",
    "    # Tokenize responses\n",
    "    mistral_tokens = mistral_response.split()\n",
    "    chatgpt_tokens = chatgpt_response.split()\n",
    "    avg_length = (len(mistral_tokens) + len(chatgpt_tokens)) // 2\n",
    "    # Taking the first half of Mistral response and the second half of ChatGPT response\n",
    "    avg_response = mistral_tokens[:avg_length] + chatgpt_tokens[avg_length:]\n",
    "    \n",
    "    return ' '.join(avg_response)\n",
    "\n",
    "\n",
    "def clean_response(response):\n",
    "    response = response.replace('\\n', ' ')\n",
    "    response = response.replace('\"', '')\n",
    "    return response\n",
    "\n",
    "json_files = ['1.json', '2.json', '3.json', '4.json', '5.json', '6.json', '7.json']\n",
    "\n",
    "# Lists to store ROUGE similarity scores\n",
    "rouge_similarity_mistral = []\n",
    "rouge_similarity_chatgpt = []\n",
    "\n",
    "counter = 0\n",
    "for file in json_files:\n",
    "    counter+=1\n",
    "    with open('/YourDirectoryToJSONFILE/GeneratedJsonFiles/'+file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        for i in range(len(json_data['question'])):\n",
    "            # Get Mistral and ChatGPT responses\n",
    "            mistral_response = json_data['mistral_response'][str(i)]\n",
    "            chatgpt_response = json_data['chatgpt_response'][str(i)]\n",
    "\n",
    "            mistral_response_cleaned_new = ''\n",
    "            chatgpt_response_cleaned = []\n",
    "            average_response_cleaned = []\n",
    "\n",
    "            \n",
    "            # Generating average response\n",
    "            average_response = generate_average_response(mistral_response, chatgpt_response)\n",
    "\n",
    "            mistral_responses_cleaned = [clean_response(response) for response in mistral_response]\n",
    "            chatgpt_responses_cleaned = [clean_response(response) for response in chatgpt_response]\n",
    "            average_responses_cleaned = [clean_response(response) for response in average_response]\n",
    "\n",
    "            average_response_string = ''.join(average_responses_cleaned)\n",
    "            mistral_response_string = ''.join(mistral_responses_cleaned)\n",
    "            chatgpt_response_string = ''.join(chatgpt_responses_cleaned)\n",
    "            print(\"Mistral Comparison\")\n",
    "            rouge_mistral = compute_rouge_similarity(mistral_response_string, average_response_string)\n",
    "            print(\"Chatgpt comparison\")\n",
    "            rouge_chatgpt = compute_rouge_similarity(chatgpt_response_string, average_response_string)\n",
    "\n",
    "            # Append ROUGE similarity scores to lists\n",
    "            rouge_similarity_mistral.append(rouge_mistral)\n",
    "            rouge_similarity_chatgpt.append(rouge_chatgpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb1826-ba70-44e7-862f-6a089156c1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiexercise",
   "language": "python",
   "name": "aiexercise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
